{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# TODO: Fill this in based on where you saved the training and testing data\n",
    "\n",
    "training_file = \"traffic-signs-data/train.p\"\n",
    "validation_file= \"traffic-signs-data/valid.p\"\n",
    "testing_file = \"traffic-signs-data/test.p\"\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 34799\n",
      "Number of testing examples = 12630\n",
      "Image data shape = (32, 32, 3)\n",
      "Number of classes = 43\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "X_train = np.array(X_train)\n",
    "X_valid = np.array(X_valid)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_valid = np.array(y_valid)\n",
    "y_test = np.array(y_test)\n",
    "# TODO: Number of training examples\n",
    "n_train = len(y_train)\n",
    "\n",
    "# TODO: Number of validation examples\n",
    "n_validation = len(y_valid)\n",
    "\n",
    "# TODO: Number of testing examples.\n",
    "n_test = len(y_test)\n",
    "\n",
    "# TODO: What's the shape of an traffic sign image?\n",
    "image_shape = X_train[0].shape\n",
    "\n",
    "# TODO: How many unique classes/labels there are in the dataset.\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f87f418ff98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Visualizations will be shown in the notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "index = random.randint(0, len(X_train))\n",
    "image = X_train[index].squeeze()\n",
    "\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "print(y_train[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAACTCAYAAACH8s4+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6pQBIEmdMgAkqVMGgCR16v8AkQhhfzbO6QYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f87bc8024a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAACTCAYAAACAnNJuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nM+glqXEGvSQ17v8AVRRsFlnAAisAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f87df8127b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "myDictionary = dict(zip(unique, counts))\n",
    "fig, ax = plt.subplots(nrows=1,ncols=1)\n",
    "plt.subplot(2,1,1)\n",
    "plt.bar(list(myDictionary.keys()), myDictionary.values(), color='g')\n",
    "plt.xlabel('train')\n",
    "\n",
    "#validation data\n",
    "unique, counts = np.unique(y_valid, return_counts=True)\n",
    "myDictionary = dict(zip(unique, counts))\n",
    "fig, ax = plt.subplots(nrows=1,ncols=1)\n",
    "plt.subplot(2,1,2)\n",
    "plt.bar(list(myDictionary.keys()), myDictionary.values(), color='g')\n",
    "plt.xlabel('validation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "def rgb2gray(rgb):\n",
    "\n",
    "    r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
    "    #gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "    #gray = (r+g+b)/3\n",
    "    gray = 0.21 * r + 0.72 * g + 0.07 * b\n",
    "    gray = gray.reshape(32,32,1)\n",
    "    return gray\n",
    "\n",
    "def conversion(list1):\n",
    "    l = []\n",
    "    for i in range(len(list1)):\n",
    "        img = list1[i] \n",
    "        gray = rgb2gray(img)\n",
    "        l.append(gray)\n",
    "    return l\n",
    "\n",
    "\n",
    "def normalise(list1):\n",
    "    l = []\n",
    "    for i in range(len(list1)):\n",
    "        img = list1[i]\n",
    "        norm = (img - 128)/128\n",
    "        l.append(norm)\n",
    "    return l\n",
    "\n",
    "x_gray = conversion(X_train)\n",
    "x_nor_gray = normalise(x_gray) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "xv_gray = conversion(X_valid)\n",
    "xv_nor_gray = normalise(xv_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "xt_gray = conversion(X_test)\n",
    "xt_nor_gray = normalise(xt_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_nor_gray[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "EPOCHS = 4\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "def LeNet(x):    \n",
    "    # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    \n",
    "    # SOLUTION: Layer 1: Convolutional. Input = 32x32x1. Output = 28x28x6.\n",
    "    conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 1, 6), mean = mu, stddev = sigma))\n",
    "    conv1_b = tf.Variable(tf.zeros(6))\n",
    "    conv1   = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n",
    "\n",
    "    # SOLUTION: Activation.\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    #conv1 = tf.nn.dropout(conv1, keep_prob)\n",
    "    #SOLUTION: Pooling. Input = 28x28x6. Output = 14x14x6.\n",
    "    #conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # SOLUTION: Layer 2: Convolutional. Output = 10x10x16.\n",
    "    ## 28x28x6 -- 24x24x16.\n",
    "    # 28,28,6 -- 24,24,16\n",
    "    conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean = mu, stddev = sigma))\n",
    "    conv2_b = tf.Variable(tf.zeros(16))\n",
    "    conv2   = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    #conv2 = tf.nn.dropout(conv2, keep_prob)\n",
    "    # SOLUTION: Pooling. Input = 10x10x16. Output = 5x5x16.\n",
    "    #conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    #24,24,16 ---19,19,24\n",
    "    conv3_W = tf.Variable(tf.truncated_normal(shape=(6, 6, 16, 24), mean = mu, stddev = sigma))\n",
    "    conv3_b = tf.Variable(tf.zeros(24))\n",
    "    conv3   = tf.nn.conv2d(conv2, conv3_W, strides=[1, 1, 1, 1], padding='VALID') + conv3_b\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    conv3 = tf.nn.relu(conv3)\n",
    "    #conv3 = tf.nn.dropout(conv3, keep_prob)\n",
    "    #19,19,24 -- 15,15,10\n",
    "    conv4_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 24, 10), mean = mu, stddev = sigma))\n",
    "    conv4_b = tf.Variable(tf.zeros(10))\n",
    "    conv4   = tf.nn.conv2d(conv3, conv4_W, strides=[1, 1, 1, 1], padding='VALID') + conv4_b\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    conv4 = tf.nn.relu(conv4)\n",
    "    #conv4 = tf.nn.dropout(conv4, keep_prob)\n",
    "    #15,15,10 --- 10,10,6\n",
    "    conv5_W = tf.Variable(tf.truncated_normal(shape=(6, 6, 10, 6), mean = mu, stddev = sigma))\n",
    "    conv5_b = tf.Variable(tf.zeros(6))\n",
    "    conv5   = tf.nn.conv2d(conv4, conv5_W, strides=[1, 1, 1, 1], padding='VALID') + conv5_b\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    conv5 = tf.nn.relu(conv5)\n",
    "    #conv5 = tf.nn.dropout(conv5, keep_prob)\n",
    "\n",
    "    # SOLUTION: Flatten. Input = 5x5x16. Output = 400.\n",
    "    ## 10x10x16 = 1600\n",
    "    #10,10,6 -- 600\n",
    "    fc0   = flatten(conv5)\n",
    "    \n",
    "    # SOLUTION: Layer 3: Fully Connected. Input = 400. Output = 120.\n",
    "    ## 600 to 400\n",
    "    fc1_W = tf.Variable(tf.truncated_normal(shape=(600, 400), mean = mu, stddev = sigma))\n",
    "    fc1_b = tf.Variable(tf.zeros(400))\n",
    "    fc1   = tf.matmul(fc0, fc1_W) + fc1_b\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    fc1    = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, keep_prob)\n",
    "\n",
    "    # SOLUTION: Layer 4: Fully Connected. Input = 120. Output = 84.\n",
    "    ## 400 -- 200\n",
    "    fc2_W  = tf.Variable(tf.truncated_normal(shape=(400,200), mean = mu, stddev = sigma))\n",
    "    fc2_b  = tf.Variable(tf.zeros(200))\n",
    "    fc2    = tf.matmul(fc1, fc2_W) + fc2_b\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    fc2    = tf.nn.relu(fc2)\n",
    "    fc2 = tf.nn.dropout(fc2, keep_prob)\n",
    "    # SOLUTION: Layer 5: Fully Connected. Input = 200. Output = 43.\n",
    "    fc3_W  = tf.Variable(tf.truncated_normal(shape=(200, 43), mean = mu, stddev = sigma))\n",
    "    fc3_b  = tf.Variable(tf.zeros(43))\n",
    "    logits = tf.matmul(fc2, fc3_W) + fc3_b\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 32, 32,1))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "one_hot_y = tf.one_hot(y, 43)\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "rate = 0.001\n",
    "\n",
    "logits = LeNet(x)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y, keep_prob: 1 })\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "EPOCH 1 ...\n",
      "Validation Accuracy = 0.919\n",
      "training Accuracy = 0.940\n",
      "\n",
      "EPOCH 2 ...\n",
      "Validation Accuracy = 0.939\n",
      "training Accuracy = 0.976\n",
      "\n",
      "EPOCH 3 ...\n",
      "Validation Accuracy = 0.952\n",
      "training Accuracy = 0.983\n",
      "\n",
      "EPOCH 4 ...\n",
      "Validation Accuracy = 0.964\n",
      "training Accuracy = 0.989\n",
      "\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(x_nor_gray)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        x_nor_gray, y_train = shuffle(x_nor_gray, y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = x_nor_gray[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y, keep_prob: 0.5})\n",
    "        training_accuracy = evaluate(x_nor_gray, y_train)    \n",
    "        validation_accuracy = evaluate(xv_nor_gray, y_valid)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print(\"training Accuracy = {:.3f}\".format(training_accuracy))\n",
    "        print()\n",
    "        \n",
    "    saver.save(sess, './lenet')\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 0.943\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "\n",
    "    test_accuracy = evaluate(xt_nor_gray, y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
